{% set name = "sacrebleu" %}
{% set version = "2.0.0" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz
  sha256: 51fb69b6683f1b9999cd180143bb6b21d7841744537c9aab235cfe676550f0cf
  patches:
    - no_changelog.patch

build:
  noarch: python
  number: 0
  script: {{ PYTHON }} -m pip install . -vv
  entry_points:
    - sacrebleu = sacrebleu.sacrebleu:main

requirements:
  host:
    - python
    - pip
    - patch  # [not win]
  run:
    - python
    - typing
    - portalocker
    - regex
    - tabulate >=0.8.9
    - numpy >=1.17
    - colorama
    # extras_require={'ja': ['mecab-python3==1.0.3', 'ipadic>=1.0,<2.0']},

test:
  imports:
    - sacrebleu
  requires:
    - pip
  commands:
    - pip check

about:
  home: https://github.com/mjpost/sacrebleu
  license: Apache-2.0
  license_file: LICENSE.txt
  summary: Reference BLEU implementation that auto-downloads test sets and reports a version string to facilitate cross-lab comparisons
  doc_url: https://github.com/mjpost/sacrebleu/blob/master/README.md
  dev_url: https://github.com/mjpost/sacrebleu

  description: |
    SacreBLEU (Post, 2018) provides hassle-free computation of shareable,
    comparable, and reproducible BLEU scores. Inspired by Rico Sennrich's
    multi-bleu-detok.perl, it produces the official WMT scores but works with
    plain text. It also knows all the standard test sets and handles
    downloading, processing, and tokenization for you.

extra:
  recipe-maintainers:
    - hmaarrfk
